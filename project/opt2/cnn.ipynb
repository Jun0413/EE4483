{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbsIQpL2gE7S"
   },
   "source": [
    "# Classification of the MNIST handwritten digits using CNNs\n",
    "In this notebook we will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the MNIST training and test datasets using torchvision\n",
    "2. Define a Neural Network (simple fully connected at first, CNN later)\n",
    "3. Define a loss function\n",
    "4. Train the network on the training split of MNIST\n",
    "5. Test the network on the test split of MNIST\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mV-ANYHVkObV"
   },
   "source": [
    "## Install Pytorch to Colab VM\n",
    "[Pytorch](https://pytorch.org) is a deep learning framework that allows you to build, train and evaluate various deep learning models, such as CNNs that we are going to work with in this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "z5Q086C-gA3g",
    "outputId": "8041dd71-fbab-4eaf-b2f2-6d2320c15ffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3\n",
      "PyTorch is already installed, good to go!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys    \n",
    "print(\"Python version: {}\".format(sys.version_info[0]))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to suppress unnecessary warnings\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(\"PyTorch is already installed, good to go!\") \n",
    "except:\n",
    "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "    accelerator = 'cu80' if os.path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "    !pip install -q \\\n",
    "      http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl \\\n",
    "      torchvision\n",
    "    print(\"Successfully installed PyTorch!\")\n",
    "    import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NiDSviI_dLAL"
   },
   "source": [
    "## Some imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ij6gipg0dKAd",
    "outputId": "e7884145-24fd-4015-bfcb-64f4f840fe48",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup is done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt  # for plots\n",
    "import numpy as np  # for working with numbers and arrays of numbers\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "import random\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "print(\"Setup is done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PrSX5XW2bnxe"
   },
   "source": [
    "# 1. Load MNIST data\n",
    "Loading the data into your python script can be a tedious process. Luckily, PyTorch allows us to load the data using the torchvision.datasets classes. It has some of the popular datasets loading proccesses written for you, including the MNIST dataset.\n",
    "The data will be downloaded to the mnist_dir folder on the virtual machine if you run this cell for the first time.\n",
    "## Transforms\n",
    "The output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1].\n",
    "PyTorch Tensors are similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n",
    "## Iterating through the dataset\n",
    "Let’s put this all together to create a dataset with composed transforms. Every time this dataset is sampled:\n",
    "\n",
    "* An image is read from the file on the fly\n",
    "* Transforms are applied on the read image\n",
    "* We can iterate over the created dataset with a for i in range loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "Ce79OzaF3X5E",
    "outputId": "bb508e6e-ab0b-49dc-8c82-c3e4a3b2249f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "0 torch.Size([1, 28, 28]) torch.Size([])\n",
      "1 torch.Size([1, 28, 28]) torch.Size([])\n",
      "2 torch.Size([1, 28, 28]) torch.Size([])\n",
      "3 torch.Size([1, 28, 28]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "mnist_dir = 'datasets/MNIST' # the directory our data will be downloaded too\n",
    "\n",
    "transformed_dataset = datasets.MNIST(mnist_dir, train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,)) # normalizing to the [-1,1] range\n",
    "                       ]))\n",
    "\n",
    "for i in range(len(transformed_dataset)):\n",
    "    sample = transformed_dataset[i]\n",
    "\n",
    "    print(i, sample[0].size(), sample[1].size())\n",
    "\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbGcOCzd3YTh"
   },
   "source": [
    "However, we are losing a lot of features by using a simple for loop to iterate over the data. In particular, we are missing out on:\n",
    "\n",
    "* Batching the data - images can be processed in bulk instead of one-by-one\n",
    "* Shuffling the data - this is a useful technique of rearranging the order of the images in which our training algorithm will pick images\n",
    "* Load the data in parallel using multiprocessing workers.\n",
    "\n",
    "`torch.utils.data.DataLoader` is an iterator which provides all these features.\n",
    "In the code below we create 2 `DataLoader` objects, one for the training data, and one for the test data\n",
    "\n",
    "To summarize, in order to load the data using PyTorch methods we need to:\n",
    "1. Apply the necessary transforms to the image, in order to make it the same size as the rest and normalized\n",
    "2. Create the `Dataset` object containing the methods to sample a training image\n",
    "3. Create the `DataLoader` object for us to easier iterate over data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bKAvxv0fHvpq",
    "outputId": "72c8899e-4ad9-4f1d-f0c2-8cbac80f9b93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MNIST data is loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_MNIST(mnist_dir, batch_size, test_batch_size, kwargs):\n",
    "\n",
    "  # Dataloader object is used to organize training data neatly into batches\n",
    "  # it is a part of the PyTorch framework\n",
    "  train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(mnist_dir, train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "  test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(mnist_dir, train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True, **kwargs)\n",
    "  \n",
    "  return train_loader, test_loader\n",
    "\n",
    "\n",
    "batch_size = 50 \n",
    "test_batch_size = 100\n",
    "mnist_dir = 'datasets/MNIST' # the directory our data will be downloaded too\n",
    "train_loader, test_loader = load_MNIST(mnist_dir, batch_size, test_batch_size, kwargs)\n",
    "print(\"The MNIST data is loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k5vIFpUC-gqq"
   },
   "source": [
    "## Look at the data\n",
    "We will sample a small subset of the training data to see what the MNIST data roughly looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "colab_type": "code",
    "id": "ET0pU2GrIEdo",
    "outputId": "9992acc8-74da-4800-c24e-e5267dda1531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One minibatch of MNIST data is a 4D array of shape torch.Size([50, 1, 28, 28])\n",
      "1st dimension (50) is the number of images in the minibatch\n",
      "2nd dimension (1) is the number of image channels\n",
      "3rd and 4th dimensions (28, 28) are the spatial size of the image\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this function is here to show an image\n",
    "def imshow(img, title=None):\n",
    "    npimg = img.numpy()\n",
    "    mean = np.array([0.1307])\n",
    "    std = np.array([0.3081])\n",
    "    npimg = std * npimg + mean # unnormalize\n",
    "    npimg = np.clip(npimg, 0, 1)\n",
    "    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "    npimg = npimg.squeeze()\n",
    "    plt.imshow(npimg)\n",
    "    plt.show\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated \n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(\"One minibatch of MNIST data is a 4D array of shape {}\".format(images.shape))\n",
    "print(\"1st dimension ({}) is the number of images in the minibatch\".format(batch_size))\n",
    "print(\"2nd dimension ({}) is the number of image channels\".format(images.shape[1]))\n",
    "print(\"3rd and 4th dimensions ({0}, {1}) are the spatial size of the image\".format(*images.shape[-2:]))\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# show one sample\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "  sample = data[0] # change number to any id in the batch \n",
    "  imshow(sample, 'random sample')\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jtAqoD4raT1h"
   },
   "source": [
    "# 2. Define the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G95eWGHgg3w1"
   },
   "source": [
    "## Fully connecter with 1 layer\n",
    "The pixels are represented as a 1D vector of size 784 and fed into a fully connected network with 10 output neurons\n",
    "![alt text](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/d5222c6e3d15770a.png)\n",
    "### Softmax \n",
    "\n",
    "We also use a softmax function to transfer scores (logits) into class probabilities. \\\\\n",
    "Entries are normalized -> sum up to 1\n",
    "\n",
    "![alt text](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/604a9797da2a48d7.png)\n",
    "\n",
    "### Note:\n",
    "The fully-connected layer can be constructed with a `nn.Linear` module, which accepts 2 parameters:\n",
    "\n",
    "* `in_channels` - number of input neurons\n",
    "* `out_channels` - number of output neurons\n",
    "For example, when we have 784 input neurons and 10 output neurons we can initialize our module the following way:\n",
    "```\n",
    "nn.Linear(784,10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wy6z4ieXgtCj"
   },
   "outputs": [],
   "source": [
    "class simpleFC(nn.Module):\n",
    "    def __init__(self, input_size=784, num_classes=10):\n",
    "        # declaring operations\n",
    "        super().__init__() # calling the inint method of the superclass (nn.Module)\n",
    "        self.fc1 = nn.Linear(input_size, num_classes) # fully-connected layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # defines the forward pass\n",
    "        x = x.view(-1, 784) # here we represent a MNIST image as a vector of pixels\n",
    "        # 784 is the total number of pixels in a 28 by 28 image\n",
    "        out = self.fc1(x) # weighted sum of input and network weights -> Wx+b, b - bias\n",
    "        return F.log_softmax(out, dim=1) # return activations after softmax layer\n",
    "    \n",
    "model = simpleFC().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N4BK36y47anC"
   },
   "source": [
    "Here we just defined the forward function. The backward function (where gradients are computed) is automatically defined for us using autograd. Any of the Tensor operations can be used in the forward function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ptC67ps3ED3"
   },
   "source": [
    "# 3. Define a Loss Function and an Optimizer\n",
    "## Loss? How cross-entropy loss is calculated? \n",
    "Loss is a way to quantifying what it means to have a “good” classifier\n",
    "![alt text](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/1d8fc59e6a674f1c.png) \n",
    "\n",
    "**Note!!!** In Pytorch obtaining log-probabilities in a neural network is easily achieved by adding a  `LogSoftmax`  layer in the last layer of your network and using `NLLLoss` (The negative log likelihood loss)\n",
    "You may use `CrossEntropyLoss` instead, if you prefer not to add an extra layer.\n",
    "\n",
    "## Optimizer\n",
    "The simplest update rule used in practice is the Stochastic Gradient Descent (SGD). This method updates all the weights of the neural net after computing the loss on one batch of images. The SGD update rule, as well as other more complicated optimizers like Nesterov-SGD, Adam, RMSProp, etc, are implemented in the torch.optim module. All you need to do is to create an optimizer variable and call its `.step` method during training. This will automatically update the weights of your network after you have computed the gradients with the `loss.backward` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbSSNEN6shYu"
   },
   "outputs": [],
   "source": [
    "# this will be the function we use later to calculate the cross entropy loss\n",
    "#loss_function = nn.CrossEntropyLoss() # use this instead if you don't use softmax activations\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # lr - learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L55dKJLmsgI3"
   },
   "source": [
    "## How to choose your learning rate?\n",
    "\n",
    "Hyperparameter - not-leranable parameter and picked manually in the begging of training \\\\\n",
    "Try and see what works best \\\\\n",
    "\n",
    "Check behavious: \n",
    "1. Simple_FC with lr = 0.01, 0.001, 0.0001\n",
    "2. Complex_FC with lr = 0.01, 0.001, 0.0001\n",
    "3. CNN with lr = 0.1, 0.01 \n",
    "\n",
    "![alt text](http://cs231n.github.io/assets/nn3/learningrates.jpeg)\n",
    "\n",
    "## What is momentum?\n",
    " - running average of previous updates! Small oscillations \n",
    " \n",
    " `V = momentum*V + (1-momentum)*gradient_of_parameters`\n",
    " \n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*5-GPmnonHVQiIj2EPG3Fgw.png)\n",
    "\n",
    "Without Momentum -> \n",
    "\n",
    "```\n",
    "update = learning_rate * gradient_of_parameters\n",
    "parameters = parameters - update\n",
    "\n",
    "```\n",
    "\n",
    "![alt text](https://qph.fs.quoracdn.net/main-qimg-7adad11c6ee947a96e917e2a8205392d)\n",
    "\n",
    "With Momentum \n",
    "```\n",
    "V = momentum*V + (1-momentum)*gradient_of_parameters\n",
    "parameters = parameters - learning_rate * V\n",
    "\n",
    "```\n",
    "\n",
    "![alt text](https://deeplearning4j.org/img/updater_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5_h8ZKz4acAq"
   },
   "source": [
    "# 4. Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JgyRYxcwvwvM",
    "outputId": "66ed8288-d022-45b9-ca36-c5c0a9aa029a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training method loaded!\n"
     ]
    }
   ],
   "source": [
    "def train(model, device, train_loader, loss_function, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # data has a batch of images\n",
    "        # target is a batch of corresponding training labels\n",
    "        optimizer.zero_grad() # initialize all the gradients with zeros\n",
    "        output = model(data) # compute the network's predictions for the batch of images\n",
    "        loss = loss_function(output, target) # here we calculate the loss value\n",
    "        loss.backward() # compute the gradients for all the weights of the network automatically!\n",
    "        optimizer.step() # here we actually update the network's weights\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))         \n",
    "print('Training method loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1054
    },
    "colab_type": "code",
    "id": "imjVX-K4TPRh",
    "outputId": "5b08883e-ff68-4c23-ba43-d124401539c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.495384\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.483837\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.437294\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.379753\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.326257\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.374313\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.423109\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.421719\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.350872\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.424521\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.331740\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.361782\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.389005\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.262778\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.217856\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.174293\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.487992\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.297962\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.392958\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.375605\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.313805\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.264075\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.159767\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.396580\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.426782\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.372187\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.120743\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.340747\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.235703\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.278660\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.242275\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.291653\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.263292\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.293407\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.285518\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.230060\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.252571\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.266983\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.317404\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.224143\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.514820\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.490459\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.233064\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.329790\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.482517\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.219054\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.367716\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.487500\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.109560\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.305275\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.241793\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.254070\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.219412\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.210968\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.128079\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.238608\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.527638\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.155022\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.097836\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.194146\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "        train(model, device, train_loader, loss_function, optimizer, epoch)\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9wrJV9Rkaj2Q"
   },
   "source": [
    "# 5. Test on the remaining 10000 images\n",
    "here we have a method to calculate how well our trained network can work on the images that it has not seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dWZ9ofjwHFky",
    "outputId": "4e33ca57-5981-4adc-d7f1-c155e76393b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test method is loaded successfully\n"
     ]
    }
   ],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('[{}/{}]\\t'\n",
    "                  'Correct: {}\\t'\n",
    "                  'Total: {}\\t'.format(\n",
    "                batch_idx,\n",
    "                len(test_loader),\n",
    "                correct,\n",
    "                total))\n",
    "    if len(test_loader.dataset)==0:\n",
    "        print(\"Error: test data have not been loaded correctly\")\n",
    "        return -1\n",
    "    \n",
    "    accuracy = 100.0 * correct / total\n",
    "\n",
    "    print('Accuracy of the network on the test images: {:.3f}%; correct: {} out of {}'.format(\n",
    "        accuracy, correct, total))\n",
    "    \n",
    "print(\"Test method is loaded successfully\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UtsiTuELHa4N"
   },
   "source": [
    "## Call the test function to get the accuracy of our model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "fCaUYDDZUnz9",
    "outputId": "95d3bc3f-3bec-4ea2-8307-3c6165d2fedd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100]\tCorrect: 91\tTotal: 100\t\n",
      "[10/100]\tCorrect: 1010\tTotal: 1100\t\n",
      "[20/100]\tCorrect: 1922\tTotal: 2100\t\n",
      "[30/100]\tCorrect: 2834\tTotal: 3100\t\n",
      "[40/100]\tCorrect: 3752\tTotal: 4100\t\n",
      "[50/100]\tCorrect: 4667\tTotal: 5100\t\n",
      "[60/100]\tCorrect: 5601\tTotal: 6100\t\n",
      "[70/100]\tCorrect: 6535\tTotal: 7100\t\n",
      "[80/100]\tCorrect: 7456\tTotal: 8100\t\n",
      "[90/100]\tCorrect: 8383\tTotal: 9100\t\n",
      "Accuracy of the network on the test images: 92.080%; correct: 9208 out of 10000\n"
     ]
    }
   ],
   "source": [
    "test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pavpnieRGmIN"
   },
   "source": [
    "## How does optimization work?\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*bl1EuPH_XEGvMcMW6ZloNg.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2GfK1kOxHmCn"
   },
   "source": [
    "# Now let's try other networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "801raMJ1ONvu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HUVDENAMg-s2"
   },
   "source": [
    "## Convolutional net with 2 conv layers\n",
    "### Conv2d\n",
    "A convolutional layer in PyTorch can be created using the nn.Conv2d function.\n",
    "Here are its some essential parameters:\n",
    "1. in_channels -  depth of the input (D1)\n",
    "2. out_channels - depth of the output (D2)\n",
    "3. kernel_size - defines both height and with of the filter (F)\n",
    "4. padding - set to 0 by default, which means no zero padding\n",
    "5. stride - set to 1 by default\n",
    "\n",
    "Example of initializing the conv2d module:\n",
    "\n",
    "```\n",
    "in_channels = 1\n",
    "out_channels = 10\n",
    "kernel_size = 5\n",
    "nn.conv2d(in_channels, out_channels, kernel_size)\n",
    "```\n",
    "The function then can be called on the 4D input tensor of size nSamples x nChannels x Height x Width, which is one batch (nSamples) of images. The call happens in the ```forward``` method of our model \n",
    "### Max pooling\n",
    "It is common to periodically insert a Pooling layer in-between successive Conv layers in a ConvNet architecture. Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network, and hence to also control overfitting.\n",
    "\n",
    "This is mainly done to fight overfitting and to lower the computational cost by reducing the number of parameters to learn. This also provides a basic translation invariance to the internal representation.\n",
    "\n",
    "Max pooling is done by applying a max filter to (usually) non-overlapping subregions of the initial representation. The most commonly used is the 2x2 max filter applied with a stride S = 2:\n",
    "![alt text](http://cs231n.github.io/assets/cnn/maxpool.jpeg)\n",
    "\n",
    "### Note! \n",
    "PyTorch `torch.nn.functional.max_pool2d` function has 2 required parameters:\n",
    "* `input` - the input image or feature map\n",
    "* `kernel_size` - the size of the max filter (we will use 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00bGzwQ73L-b"
   },
   "source": [
    "### In the following section we can check the shapes of different feature maps starting from the input 4D tensor (nSamples x nChannels x Height x Width) and going all the way to the output activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "rcGmdabk9h6E",
    "outputId": "1fcd4b3f-277f-45c5-b669-97625f815770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original input size:\t torch.Size([1, 1, 28, 28])\n",
      "Size after conv1:\t torch.Size([1, 10, 24, 24])\n",
      "Size after max pool 1:\t torch.Size([1, 10, 12, 12])\n",
      "Size after conv2:\t torch.Size([1, 20, 8, 8])\n",
      "Size after max pool 2:\t torch.Size([1, 20, 4, 4])\n",
      "Size before fc1:\t torch.Size([1, 320])\n",
      "Size after fc1:\t\t torch.Size([1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2987, -1.6621, -2.8336, -2.2006, -2.9512, -2.2760, -1.9808, -2.3428,\n",
       "         -2.4806, -2.6933]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class exampleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)  # first convolutional layer\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # second convolutional layer\n",
    "        self.fc1 = nn.Linear(20*4*4, 10) # fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Original input size:\\t {}\".format(x.shape))\n",
    "        x = self.conv1(x)\n",
    "        print(\"Size after conv1:\\t {}\".format(x.shape))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        print(\"Size after max pool 1:\\t {}\".format(x.shape))\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        print(\"Size after conv2:\\t {}\".format(x.shape))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        print(\"Size after max pool 2:\\t {}\".format(x.shape))\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 16*20)\n",
    "        print(\"Size before fc1:\\t {}\".format(x.shape))\n",
    "        x = self.fc1(x)\n",
    "        print(\"Size after fc1:\\t\\t {}\".format(x.shape))\n",
    "        return F.log_softmax(x, dim=1)   \n",
    "    \n",
    "example_model = exampleCNN().to(device)\n",
    "\n",
    "batch = torch.stack((sample,)*1, 0) # just one image in a batch for example\n",
    "batch.shape\n",
    "example_model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjaL4Pe94SVk"
   },
   "source": [
    "### 2b. Define a CNN network\n",
    "Now let's rewrite the same network without the ```print``` calls, so that they won't clutter our log when we are doing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCP42dxRlCUs"
   },
   "outputs": [],
   "source": [
    "class simpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)  # first convolutional layer\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # second convolutional layer\n",
    "        self.fc1 = nn.Linear(320, 10) # fully connected layer, \n",
    "        # why the first parameter is set to 320??? Think about it\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=1)   \n",
    "    \n",
    "cnn_model = simpleCNN().to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wtkaAUdtEK3p"
   },
   "source": [
    "### 3b. Define the Loss and optimizer\n",
    "### 4b. Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "vjoEfggWEK_P",
    "outputId": "8464df7d-8836-4013-cc48-eb6f08f46034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.146896\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.012856\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.073910\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.047947\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.040577\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.023476\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.051140\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.166916\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.026108\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.005224\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.106935\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.011023\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.011139\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.064827\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.005050\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.064101\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.012161\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.040846\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.027635\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.022799\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.056130\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.193463\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.052373\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.066783\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.009760\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.041697\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.026686\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.110647\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.012568\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.010722\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.011279\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.104865\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.073970\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.017448\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.073058\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.019785\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.032007\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.123076\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.007190\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.029870\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.013847\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.012447\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.037190\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.069047\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.020425\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.027150\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.117244\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.013817\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.037934\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.008292\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.012590\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.071868\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.008087\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.041770\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.018796\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.102281\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.026473\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.018503\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.018887\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.034738\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(cnn_model.parameters(), lr=0.001, momentum=0.9) # lr - learning rate\n",
    "num_epochs = 5\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "        train(cnn_model, device, train_loader, loss_function, optimizer, epoch)\n",
    "print('Training finished')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V0HMgqycLf7P"
   },
   "source": [
    "### 5b. and test it to get the final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "FgfGjVSyLlU7",
    "outputId": "e0e09502-54f8-496e-ede1-a344ceb30fe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100]\tCorrect: 98\tTotal: 100\t\n",
      "[10/100]\tCorrect: 1087\tTotal: 1100\t\n",
      "[20/100]\tCorrect: 2073\tTotal: 2100\t\n",
      "[30/100]\tCorrect: 3054\tTotal: 3100\t\n",
      "[40/100]\tCorrect: 4038\tTotal: 4100\t\n",
      "[50/100]\tCorrect: 5026\tTotal: 5100\t\n",
      "[60/100]\tCorrect: 6013\tTotal: 6100\t\n",
      "[70/100]\tCorrect: 6997\tTotal: 7100\t\n",
      "[80/100]\tCorrect: 7985\tTotal: 8100\t\n",
      "[90/100]\tCorrect: 8973\tTotal: 9100\t\n",
      "Accuracy of the network on the test images: 98.620%; correct: 9862 out of 10000\n"
     ]
    }
   ],
   "source": [
    "test(cnn_model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ccSIhvyPhEzf"
   },
   "source": [
    "## [Optional] Your beast network that will get more than 99% accuracy on the test split\n",
    "Your code here! Modify the method below. You can start with the suggested code or rewrite your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfqKvnCGhHqR"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        ########################################################################\n",
    "        # modify code here:\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # first convolutional layer\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1) # second convolutional layer\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64*7*7, 512) # fully connected layer 1\n",
    "        self.fc2 = nn.Linear(512, 512) # fully connected layer 2\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.bn5 = nn.BatchNorm1d(512)\n",
    "        self.bn6 = nn.BatchNorm1d(512)\n",
    "        ########################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ########################################################################\n",
    "        # modify code here:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.dropout(x)\n",
    "        x = x.view(-1, 64*7*7)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn5(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn6(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        ########################################################################\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "cnn_model_2 = CNN().to(device)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-guaSYiLpuy"
   },
   "source": [
    "### 3c. Define a Loss and an Optimizer\n",
    "### 4c. Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1054
    },
    "colab_type": "code",
    "id": "GcWWgJhTLpu0",
    "outputId": "1231a8f0-7e7b-49a0-db99-995459ea67a9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.002971\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.002103\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.080375\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.004312\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.013984\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.021927\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.015353\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.013339\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.051983\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.033669\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.031852\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.017887\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.009122\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.006382\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.023941\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.006403\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.017887\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.001551\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.007749\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.085137\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.010380\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.125484\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.012200\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.008173\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.001910\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.003907\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.002687\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.027342\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.005483\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.007117\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.003055\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.016762\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.001408\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.033524\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.021311\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.007158\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.010710\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.004855\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.001972\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.002093\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.005709\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.077644\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.000282\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.025622\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.000384\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.044862\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.007851\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.203622\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.069173\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.000114\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.076563\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.065803\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.001963\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.000498\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.013656\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.001962\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.000983\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.000370\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.013748\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.001644\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(cnn_model_2.parameters(), lr=0.003) # lr - learning rate\n",
    "num_epochs = 5\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "        train(cnn_model_2, device, train_loader, loss_function, optimizer, epoch)\n",
    "print('Training finished') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zGVuZURqLpu2"
   },
   "source": [
    "### 5c. and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "u9dsMdDlLpu3",
    "outputId": "0578e9ca-630a-4e5f-cf2a-5fd645f75283",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100]\tCorrect: 98\tTotal: 100\t\n",
      "[10/100]\tCorrect: 1089\tTotal: 1100\t\n",
      "[20/100]\tCorrect: 2082\tTotal: 2100\t\n",
      "[30/100]\tCorrect: 3075\tTotal: 3100\t\n",
      "[40/100]\tCorrect: 4069\tTotal: 4100\t\n",
      "[50/100]\tCorrect: 5065\tTotal: 5100\t\n",
      "[60/100]\tCorrect: 6054\tTotal: 6100\t\n",
      "[70/100]\tCorrect: 7046\tTotal: 7100\t\n",
      "[80/100]\tCorrect: 8037\tTotal: 8100\t\n",
      "[90/100]\tCorrect: 9033\tTotal: 9100\t\n",
      "Accuracy of the network on the test images: 99.230%; correct: 9923 out of 10000\n"
     ]
    }
   ],
   "source": [
    "test(cnn_model_2, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "wtkaAUdtEK3p"
   ],
   "name": "CNN_training-2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
